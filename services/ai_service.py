import os
import requests
import base64
import logging
from services.weather_service import check_rain_forecast
from services.huggingface_vision import analyze_plant_with_huggingface

logger = logging.getLogger(__name__)

def format_farmer_response(ai_response):
    """Format AI response for better farmer readability"""
    try:
        # This function is now simplified since diagnosis extraction is handled in analyze_plant_image
        formatted_treatment = format_treatment_text(ai_response)
        return {
            'diagnosis': "ЁЯФН рдкреМрдзреЗ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкреВрд░рд╛ (Plant Analysis Complete)",
            'treatment': formatted_treatment
        }
        
    except Exception as e:
        logger.error(f"Error formatting farmer response: {str(e)}")
        return {
            'diagnosis': "ЁЯФН рдкреМрдзреЗ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкреВрд░рд╛ (Plant Analysis Complete)",
            'treatment': ai_response
        }

def format_treatment_text(text):
    """Format treatment text with better structure and emojis"""
    try:
        # Split into sections and add proper formatting
        sections = text.split('\n\n')
        formatted_sections = []
        
        for section in sections:
            if not section.strip():
                continue
                
            # Add emojis based on content
            if any(keyword in section.lower() for keyword in ['organic', 'рдЬреИрд╡рд┐рдХ', 'neem', 'рдиреАрдо']):
                if not section.startswith('ЁЯМ┐'):
                    section = f"ЁЯМ┐ **рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░ (Organic Treatment):**\n{section}"
            elif any(keyword in section.lower() for keyword in ['chemical', 'рд░рд╛рд╕рд╛рдпрдирд┐рдХ', 'pesticide', 'fungicide']):
                if not section.startswith('ЁЯТК'):
                    section = f"ЁЯТК **рд░рд╛рд╕рд╛рдпрдирд┐рдХ рдЙрдкрдЪрд╛рд░ (Chemical Treatment):**\n{section}"
            elif any(keyword in section.lower() for keyword in ['prevention', 'рд░реЛрдХрдерд╛рдо', 'avoid', 'рдмрдЪрд╛рд╡']):
                if not section.startswith('ЁЯЫбя╕П'):
                    section = f"ЁЯЫбя╕П **рд░реЛрдХрдерд╛рдо (Prevention):**\n{section}"
            elif any(keyword in section.lower() for keyword in ['timing', 'time', 'рд╕рдордп', 'when']):
                if not section.startswith('тП░'):
                    section = f"тП░ **рд╕рд╣реА рд╕рдордп (Best Timing):**\n{section}"
            elif any(keyword in section.lower() for keyword in ['cost', 'price', 'рд▓рд╛рдЧрдд', 'рдЦрд░реНрдЪ']):
                if not section.startswith('ЁЯТ░'):
                    section = f"ЁЯТ░ **рд▓рд╛рдЧрдд (Cost Information):**\n{section}"
            elif any(keyword in section.lower() for keyword in ['disease', 'pest', 'рд░реЛрдЧ', 'рдХреАрдЯ']):
                if not section.startswith('ЁЯФН'):
                    section = f"ЁЯФН **рд╕рдорд╕реНрдпрд╛ рдХреА рдкрд╣рдЪрд╛рди (Problem Identification):**\n{section}"
            
            formatted_sections.append(section.strip())
        
        # Join sections with proper spacing
        formatted = '\n\n'.join(formatted_sections)
        
        # Add final note if no cost information
        if not any(keyword in formatted.lower() for keyword in ['cost', 'рд▓рд╛рдЧрдд', 'рдЦрд░реНрдЪ']):
            formatted += "\n\nЁЯТ░ **рд▓рд╛рдЧрдд рдХреА рдЬрд╛рдирдХрд╛рд░реА:** рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред"
        
        return formatted.strip()
        
    except Exception as e:
        logger.error(f"Error formatting treatment text: {str(e)}")
        return text

def analyze_plant_image(image_path, weather_data=None):
    """Analyze plant image using Gemini Vision API as primary method"""
    
    # Use Gemini Vision API as primary method
    gemini_key = os.getenv('GEMINI_API_KEY', 'AIzaSyCVchsFQ9RyH4wdM2qrVZqRBJyQ5g9qOKg')
    
    try:
        # Read and encode image
        with open(image_path, 'rb') as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # Detect image format
        from PIL import Image
        img = Image.open(image_path)
        img_format = img.format.lower()
        mime_type = f"image/{img_format}" if img_format in ['jpeg', 'jpg', 'png', 'webp'] else "image/jpeg"
        
        # Clean Hindi-only structured prompt
        prompt = """рдЗрд╕ рдкреМрдзреЗ рдХреА рддрд╕реНрд╡реАрд░ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ рдФрд░ рдмрд┐рд▓реНрдХреБрд▓ рдЗрд╕реА рдлреЙрд░реНрдореЗрдЯ рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВ:

ЁЯФН **рд╕рдорд╕реНрдпрд╛ рдХреА рдкрд╣рдЪрд╛рди:**
рдХреАрдЯ рдХреЗ рдЕрдВрдбреЗ рдпрд╛ рд╕рдлреЗрдж рдордХреНрдЦреА рдХреА рд╕рдорд╕реНрдпрд╛ рджрд┐рдЦ рд░рд╣реА рд╣реИ

ЁЯМ┐ **рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░:**
тАв рдиреАрдо рдХрд╛ рддреЗрд▓: 10 рдорд┐рд▓реА рдкреНрд░рддрд┐ рд▓реАрдЯрд░ рдкрд╛рдиреА рдореЗрдВ рдорд┐рд▓рд╛рдХрд░ рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВ
тАв рдЧреЛрдмрд░ рдХрд╛ рдШреЛрд▓: 1 рдХрд┐рд▓реЛ рдЧреЛрдмрд░ рдХреЛ 10 рд▓реАрдЯрд░ рдкрд╛рдиреА рдореЗрдВ рдШреЛрд▓рдХрд░ рдЫрд╛рдиреЗрдВ
тАв рд╣рд░реА рдкрддреНрддрд┐рдпреЛрдВ рдХрд╛ рдХрд╛рдврд╝рд╛: рдиреАрдо, рддреБрд▓рд╕реА рдХреА рдкрддреНрддрд┐рдпрд╛рдВ рдЙрдмрд╛рд▓рдХрд░ рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВ

ЁЯТК **рд░рд╛рд╕рд╛рдпрдирд┐рдХ рдЙрдкрдЪрд╛рд░:**
тАв рдЗрдорд┐рдбрд╛рдХреНрд▓реЛрдкреНрд░рд┐рдб: рд▓реЗрдмрд▓ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдорд╛рддреНрд░рд╛ рдХрд╛ рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВ
тАв рдХреНрд▓реЛрд░реЛрдкрд╛рдпрд░рд┐рдлреЙрд╕: рднрд╛рд░рдд рдореЗрдВ рдЙрдкрд▓рдмреНрдз рд╣реИ
тАв рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рджреБрдХрд╛рди рд╕реЗ рд╕рд▓рд╛рд╣ рд▓реЗрдВ

тП░ **рд╕рд╣реА рд╕рдордп:**
тАв рд╕реБрдмрд╣ рдЬрд▓реНрджреА рдпрд╛ рд╢рд╛рдо рдХреЗ рд╕рдордп рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВ
тАв рдзреВрдк рддреЗрдЬ рди рд╣реЛ рддрдм рдХрд░реЗрдВ
тАв рдмрд╛рд░рд┐рд╢ рд╕реЗ рдкрд╣рд▓реЗ рди рдХрд░реЗрдВ

ЁЯЫбя╕П **рд░реЛрдХрдерд╛рдо:**
тАв рдлрд╕рд▓ рдЪрдХреНрд░ рдЕрдкрдирд╛рдПрдВ
тАв рдЦрд░рдкрддрд╡рд╛рд░ рдирд┐рдпрдВрддреНрд░рдг рдХрд░реЗрдВ
тАв рдЦреЗрдд рдХреА рд╕рдлрд╛рдИ рд░рдЦреЗрдВ
тАв рдирд┐рдпрдорд┐рдд рдирд┐рдЧрд░рд╛рдиреА рдХрд░реЗрдВ

ЁЯТ░ **рд▓рд╛рдЧрдд:**
тАв рдЕрдиреБрдорд╛рдирд┐рдд рдЦрд░реНрдЪ: тВ╣500-1000 рдкреНрд░рддрд┐ рдПрдХрдбрд╝
тАв рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░ рд╕рд╕реНрддрд╛ рд╣реИ

рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рдореЗрдВ рд╕рд░рд▓ рднрд╛рд╖рд╛ рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВред"""
        
        # Use Gemini 1.5 Flash Vision API
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={gemini_key}"
        headers = {"Content-Type": "application/json"}
        
        data = {
            "contents": [{
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": image_data
                        }
                    }
                ]
            }]
        }
        
        response = requests.post(url, json=data, headers=headers, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            
            if 'candidates' in result and len(result['candidates']) > 0:
                candidate = result['candidates'][0]
                
                if 'content' in candidate and 'parts' in candidate['content']:
                    ai_response = candidate['content']['parts'][0]['text']
                    
                    # Extract diagnosis - look for content after problem identification
                    lines = ai_response.split('\n')
                    diagnosis = ""
                    treatment = ai_response
                    
                    # Find the line after problem identification header
                    for i, line in enumerate(lines):
                        if 'ЁЯФН' in line and ('рд╕рдорд╕реНрдпрд╛' in line or 'рдкрд╣рдЪрд╛рди' in line):
                            # Get the next non-empty line as diagnosis
                            for j in range(i+1, len(lines)):
                                next_line = lines[j].strip()
                                if next_line and not next_line.startswith('ЁЯФН') and not next_line.startswith('**'):
                                    diagnosis = next_line
                                    break
                            break
                    
                    # Fallback: look for any meaningful content about pest/disease
                    if not diagnosis:
                        for line in lines:
                            line_clean = line.strip()
                            if ('рдХреАрдбрд╝' in line_clean or 'рдХреАрдЯ' in line_clean or 'рд░реЛрдЧ' in line_clean or 'рдмреАрдорд╛рд░реА' in line_clean) and len(line_clean) > 20:
                                diagnosis = line_clean
                                break
                    
                    # Final fallback
                    if not diagnosis:
                        diagnosis = "ЁЯФН рдкреМрдзреЗ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкреВрд░рд╛ (Plant Analysis Complete)"
                    
                    return {
                        'diagnosis': diagnosis,
                        'treatment': treatment,
                        'confidence': 'рдЙрдЪреНрдЪ (High)',
                        'model': 'Gemini 1.5 Flash Vision'
                    }
                else:
                    return get_fallback_analysis()
            else:
                return get_fallback_analysis()
        else:
            logger.error(f"Gemini API error: {response.status_code} - {response.text}")
            
            if response.status_code == 429:
                return {
                    'diagnosis': "API quota exceeded",
                    'treatment': "Gemini API quota limit reached. Please wait or try again later.",
                    'error': 'Gemini API quota exceeded'
                }
            return get_fallback_analysis()
            
    except Exception as e:
        logger.error(f"Gemini Vision API failed: {str(e)}")
        return get_fallback_analysis()

    # Fallback to Hugging Face if Gemini fails
    try:
        result = analyze_plant_with_huggingface(image_path)
        if not result.get('error'):
            if weather_data:
                has_rain, rain_message = check_rain_forecast(weather_data)
                if has_rain:
                    result['weather_warning'] = f"тЪая╕П Weather Alert: {rain_message}. Avoid spraying treatments before rain."
            return result
    except Exception as e:
        logger.warning(f"Hugging Face fallback failed: {str(e)}")

    # Final fallback
    return get_ai_error()

def parse_ai_response(ai_response):
    """Parse AI response into structured format"""
    try:
        # Split response into sections
        sections = ai_response.split('\n\n')
        
        diagnosis = ""
        treatment = ""
        
        # Extract diagnosis (usually in first section)
        for section in sections:
            if any(keyword in section.lower() for keyword in ['disease', 'pest', 'identification', 'diagnosis']):
                diagnosis = section.strip()
                break
        
        if not diagnosis and sections:
            diagnosis = sections[0].strip()
        
        # Extract treatment advice (combine organic and chemical sections)
        treatment_sections = []
        for section in sections:
            if any(keyword in section.lower() for keyword in ['treatment', 'organic', 'chemical', 'remedy', 'control']):
                treatment_sections.append(section.strip())
        
        treatment = '\n\n'.join(treatment_sections) if treatment_sections else ai_response
        
        return {
            'diagnosis': diagnosis or "Analysis completed - see treatment recommendations",
            'treatment': treatment or ai_response,
            'confidence': 'High'  # Default confidence
        }
        
    except Exception as e:
        logger.error(f"Error parsing AI response: {str(e)}")
        return {
            'diagnosis': "Plant health analysis completed",
            'treatment': ai_response,
            'confidence': 'Medium'
        }

def process_contextual_query(query, language, user_crops, pin_code, scan_result=None, weather_data=None, market_data=None):
    """Enhanced contextual query processing with comprehensive context awareness"""
    
    try:
        from services.enhanced_voice_assistant import enhanced_voice_assistant
        
        # Use enhanced voice assistant for better contextual responses
        response = enhanced_voice_assistant.process_contextual_query(
            query=query,
            language=language,
            user_crops=user_crops,
            pin_code=pin_code,
            scan_result=scan_result,
            weather_data=weather_data,
            market_data=market_data
        )
        
        return response
        
    except Exception as e:
        logger.error(f"Enhanced contextual query error: {str(e)}")
        
        # Fallback to original implementation
        try:
            gemini_key = os.getenv('GEMINI_API_KEY', 'AIzaSyCVchsFQ9RyH4wdM2qrVZqRBJyQ5g9qOKg')
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={gemini_key}"
            headers = {"Content-Type": "application/json"}
            
            # Build context from scan result
            context = ""
            if scan_result and scan_result.get('diagnosis'):
                context = f"рдкреМрдзреЗ рдХреА рд╕рдорд╕реНрдпрд╛: {scan_result.get('diagnosis', '')}\nрд╕реБрдЭрд╛рдпрд╛ рдЧрдпрд╛ рдЗрд▓рд╛рдЬ: {scan_result.get('treatment', '')}\n"
                if scan_result.get('weather_warning'):
                    context += f"рдореМрд╕рдо рдЪреЗрддрд╛рд╡рдиреА: {scan_result.get('weather_warning')}\n"
            
            # Create contextual prompt
            prompt = f"""{context}
рдХрд┐рд╕рд╛рди рдХрд╛ рд╕рд╡рд╛рд▓: {query}

рдКрдкрд░ рджреА рдЧрдИ рдкреМрдзреЗ рдХреА рд╕рдорд╕реНрдпрд╛ рдФрд░ рдЗрд▓рд╛рдЬ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдХрд┐рд╕рд╛рди рдХреЗ рд╕рд╡рд╛рд▓ рдХрд╛ рдЬрд╡рд╛рдм рджреЗрдВред рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рдореЗрдВ 2-3 рд╡рд╛рдХреНрдпреЛрдВ рдореЗрдВ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд╕рд▓рд╛рд╣ рджреЗрдВред"""
            
            data = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"temperature": 0.7, "maxOutputTokens": 150}
            }
            
            response = requests.post(url, json=data, headers=headers, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    return result['candidates'][0]['content']['parts'][0]['text'].strip()
            
            raise Exception("No response from AI")
            
        except Exception as fallback_error:
            logger.error(f"Fallback contextual query error: {str(fallback_error)}")
            return "рдЗрд╕ рд╕рдорд╕реНрдпрд╛ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред"

def process_voice_query(query, language, user_crops, pin_code, weather_data=None, market_data=None):
    """Enhanced voice query processing with comprehensive context"""
    
    try:
        from services.enhanced_voice_assistant import enhanced_voice_assistant
        
        # Use enhanced voice assistant for better responses
        response = enhanced_voice_assistant.process_contextual_query(
            query=query,
            language=language,
            user_crops=user_crops,
            pin_code=pin_code,
            scan_result=None,
            weather_data=weather_data,
            market_data=market_data
        )
        
        return response
        
    except Exception as e:
        logger.error(f"Enhanced voice query error: {str(e)}")
        
        # Fallback to original implementation
        try:
            # Use Gemini API for chatbot
            gemini_key = os.getenv('GEMINI_API_KEY', 'AIzaSyCVchsFQ9RyH4wdM2qrVZqRBJyQ5g9qOKg')
            
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={gemini_key}"
            headers = {"Content-Type": "application/json"}
            
            # Enhanced context-aware prompts for scanner results page
            query_lower = query.lower()
            
            if any(word in query_lower for word in ['often', 'frequency', 'рдХрд┐рддрдиреА рдмрд╛рд░', 'how many times']):
                prompt = f"""рдХрд┐рд╕рд╛рди рдкреВрдЫ рд░рд╣рд╛ рд╣реИ рдХрд┐ рдЗрд▓рд╛рдЬ рдХрд┐рддрдиреА рдмрд╛рд░ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП: {query}

рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░ рдХреЗ рд▓рд┐рдП: рд╣рд░ 7-10 рджрд┐рди рдореЗрдВ рдПрдХ рдмрд╛рд░ред рд░рд╛рд╕рд╛рдпрдирд┐рдХ рдЙрдкрдЪрд╛рд░ рдХреЗ рд▓рд┐рдП: рд▓реЗрдмрд▓ рдХреЗ рдЕрдиреБрд╕рд╛рд░, рдЖрдорддреМрд░ рдкрд░ 10-14 рджрд┐рди рдХрд╛ рдЕрдВрддрд░рд╛рд▓ред рд╕реБрдмрд╣ рдпрд╛ рд╢рд╛рдо рдХрд╛ рд╕рдордп рдмреЗрд╣рддрд░ рд╣реИред рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рдореЗрдВ 2-3 рд╡рд╛рдХреНрдпреЛрдВ рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВред"""
            
            elif any(word in query_lower for word in ['neem', 'рдиреАрдо', 'organic', 'рдЬреИрд╡рд┐рдХ']):
                prompt = f"""рдХрд┐рд╕рд╛рди рдиреАрдо рдпрд╛ рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫ рд░рд╣рд╛ рд╣реИ: {query}

рдиреАрдо рдХрд╛ рддреЗрд▓ 10 рдорд┐рд▓реА рдкреНрд░рддрд┐ рд▓реАрдЯрд░ рдкрд╛рдиреА рдореЗрдВ рдорд┐рд▓рд╛рдПрдВред рд╣рдлреНрддреЗ рдореЗрдВ рдПрдХ рдмрд╛рд░ рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВред рдЕрдиреНрдп рдЬреИрд╡рд┐рдХ рд╡рд┐рдХрд▓реНрдк: рдЧреЛрдмрд░ рдХрд╛ рдШреЛрд▓, рд╣рд▓реНрджреА рдХрд╛ рдкреЗрд╕реНрдЯ, рд▓рд╣рд╕реБрди-рдорд┐рд░реНрдЪ рдХрд╛ рдШреЛрд▓ред рд╕рд┐рд░реНрдл рд╣рд┐рдВрджреА рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВред"""
            
            else:
                # General farming question
                prompt = f"""рдЖрдк рдПрдХ рдЕрдиреБрднрд╡реА рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╣реИрдВред рдХрд┐рд╕рд╛рди рдХрд╛ рд╕рд╡рд╛рд▓: {query}

рдХреГрдкрдпрд╛ рдЗрд╕ рд╕рд╡рд╛рд▓ рдХрд╛ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдФрд░ рдЙрдкрдпреЛрдЧреА рдЬрд╡рд╛рдм рд╣рд┐рдВрджреА рдореЗрдВ рджреЗрдВред рд╕рд░рд▓ рднрд╛рд╖рд╛ рдореЗрдВ 2-3 рд╡рд╛рдХреНрдпреЛрдВ рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВ рдЬреЛ рдПрдХ рдХрд┐рд╕рд╛рди рдЖрд╕рд╛рдиреА рд╕реЗ рд╕рдордЭ рд╕рдХреЗред"""
            
            data = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 150
                }
            }
            
            response = requests.post(url, json=data, headers=headers, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    ai_response = result['candidates'][0]['content']['parts'][0]['text']
                    return ai_response.strip()
                else:
                    raise Exception("No response from Gemini")
            else:
                logger.error(f"Gemini API error: {response.status_code} - {response.text}")
                raise Exception(f"Gemini API error: {response.status_code}")
                
        except Exception as fallback_error:
            logger.error(f"Fallback voice query error: {str(fallback_error)}")
            # Provide contextual fallback responses
            if any(word in query.lower() for word in ['neem', 'рдиреАрдо']):
                return "рдиреАрдо рдХрд╛ рддреЗрд▓ 10 рдорд┐рд▓реА рдкреНрд░рддрд┐ рд▓реАрдЯрд░ рдкрд╛рдиреА рдореЗрдВ рдорд┐рд▓рд╛рдХрд░ рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВред рд╕реБрдмрд╣ рдпрд╛ рд╢рд╛рдо рдХрд╛ рд╕рдордп рдмреЗрд╣рддрд░ рд╣реИред"
            elif any(word in query.lower() for word in ['time', 'рд╕рдордп']):
                return "рд╕реБрдмрд╣ 6-9 рдмрдЬреЗ рдпрд╛ рд╢рд╛рдо 5-7 рдмрдЬреЗ рдЫрд┐рдбрд╝рдХрд╛рд╡ рдХрд░реЗрдВред рджреЛрдкрд╣рд░ рдХреА рдзреВрдк рдореЗрдВ рди рдХрд░реЗрдВред"
            else:
                return "рдХреБрдЫ рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛ рд╣реИред рдХреГрдкрдпрд╛ рджреЛрдмрд╛рд░рд╛ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВ рдпрд╛ рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред"

def get_groq_response(prompt):
    """Get response using Gemini API"""
    return process_voice_query(prompt, 'hi-IN', [], '110001')

def get_fallback_analysis():
    """Return basic plant health advice when AI fails"""
    return {
        'diagnosis': "рдкреМрдзреЗ рдХреА рд╕реНрд╡рд╛рд╕реНрдереНрдп рдЬрд╛рдВрдЪ - рдмреБрдирд┐рдпрд╛рджреА рд╡рд┐рд╢реНрд▓реЗрд╖рдг (Plant Health Check - Basic Analysis)",
        'treatment': """ЁЯМ┐ **рдЬреИрд╡рд┐рдХ рджреЗрдЦрднрд╛рд▓ (Organic Care):**
тАв рдиреАрдо рдХрд╛ рддреЗрд▓ (10 рдорд┐рд▓реА рдкреНрд░рддрд┐ рд▓реАрдЯрд░ рдкрд╛рдиреА) - рд╕рд╛рдкреНрддрд╛рд╣рд┐рдХ рдЫрд┐рдбрд╝рдХрд╛рд╡
тАв рдкреАрд▓реЗ, рдзрдмреНрдмреЗрджрд╛рд░, рдпрд╛ рдореБрд░рдЭрд╛рдиреЗ рд╡рд╛рд▓реЗ рдкрддреНрддреЛрдВ рдХреА рдЬрд╛рдВрдЪ рдХрд░реЗрдВ
тАв рдЙрдЪрд┐рдд рдкрд╛рдиреА рджреЗрдВ - рдорд┐рдЯреНрдЯреА рдирдо рд╣реЛ рд▓реЗрдХрд┐рди рдЬрд▓рднрд░рд╛рд╡ рди рд╣реЛ
тАв рдорд░реЗ рдпрд╛ рд░реЛрдЧрдЧреНрд░рд╕реНрдд рднрд╛рдЧреЛрдВ рдХреЛ рддреБрд░рдВрдд рд╣рдЯрд╛ рджреЗрдВ

ЁЯТК **рд░рд╛рд╕рд╛рдпрдирд┐рдХ рд╡рд┐рдХрд▓реНрдк (Chemical Options):**
тАв рдХреЙрдкрд░ рд╕рд▓реНрдлреЗрдЯ рдШреЛрд▓ (2 рдЧреНрд░рд╛рдо рдкреНрд░рддрд┐ рд▓реАрдЯрд░) рдлрдВрдЧрд▓ рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЗ рд▓рд┐рдП
тАв рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╕реНрддрд╛рд░ рдЕрдзрд┐рдХрд╛рд░реА рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВ

ЁЯЫбя╕П **рд░реЛрдХрдерд╛рдо (Prevention):**
тАв рдорд┐рдЯреНрдЯреА рдХреЗ рд╕реНрддрд░ рдкрд░ рдкрд╛рдиреА рджреЗрдВ, рдкрддреНрддрд┐рдпреЛрдВ рдХреЛ рдЧреАрд▓рд╛ рдХрд░рдиреЗ рд╕реЗ рдмрдЪреЗрдВ
тАв рдкреМрдзреЛрдВ рдХреЗ рдЖрд╕рдкрд╛рд╕ рдЕрдЪреНрдЫрд╛ рд╣рд╡рд╛ рдкреНрд░рд╡рд╛рд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ
тАв рд╕рдорд╕реНрдпрд╛ рдХреА рд╢реБрд░реБрдЖрддреА рдкрд╣рдЪрд╛рди рдХреЗ рд▓рд┐рдП рдирд┐рдпрдорд┐рдд рдЬрд╛рдВрдЪ рдХрд░реЗрдВ

ЁЯУЭ **рдиреЛрдЯ:** рд╕рдЯреАрдХ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рддрд╕реНрд╡реАрд░ рджреЛрдмрд╛рд░рд╛ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ рдпрд╛ рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕реЗ рд╕рд▓рд╛рд╣ рд▓реЗрдВред""",
        'confidence': 'рдмреБрдирд┐рдпрд╛рджреА (Basic)',
        'model': 'Fallback Analysis'
    }

def get_ai_error():
    """Return error when AI service fails"""
    return {
        'diagnosis': "рдПрдЖрдИ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд╕реЗрд╡рд╛ рдЕрдиреБрдкрд▓рдмреНрдз (AI analysis service unavailable)",
        'treatment': "рдЗрд╕ рд╕рдордп рдкреМрдзреЗ рдХреА рддрд╕реНрд╡реАрд░ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдирд╣реАрдВ рд╣реЛ рд╕рдХрд╛ред рдХреГрдкрдпрд╛ рдЕрдкрдиреЗ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрд╢рди рдХреА рдЬрд╛рдВрдЪ рдХрд░реЗрдВ рдФрд░ рдмрд╛рдж рдореЗрдВ рдкреБрди: рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред",
        'error': 'AI service temporarily unavailable. Please try again later.'
    }